#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Agentic RAG CLIåº”ç”¨
æ”¯æŒå¤šè·³æ¨ç†çš„å‘½ä»¤è¡Œç•Œé¢
"""

import argparse
import json
import logging
import sys
from pathlib import Path
from typing import Dict, Any

from models.multi_agent_rag import MultiAgentRAGSystem
from services.vector_store import VectorStoreService
from utils.document_processor import DocumentProcessor
from config.settings import (
    DEEPSEEK_API_KEY,
    DEFAULT_SIMILARITY_THRESHOLD,
    VECTOR_STORE_PATH
)

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class AgenticRAGCLI:
    """
    Agentic RAGå‘½ä»¤è¡Œåº”ç”¨
    """
    
    def __init__(self):
        self.vector_store = VectorStoreService()
        self.document_processor = DocumentProcessor()
        self.rag_system = MultiAgentRAGSystem(self.vector_store)
        
    def setup_knowledge_base(self, documents_path: str = None):
        """
        è®¾ç½®çŸ¥è¯†åº“
        
        Args:
            documents_path: æ–‡æ¡£è·¯å¾„ï¼ˆå¯é€‰ï¼‰
        """
        print("ğŸ”§ æ­£åœ¨è®¾ç½®çŸ¥è¯†åº“...")
        
        if documents_path and Path(documents_path).exists():
            print(f"ğŸ“ ä» {documents_path} åŠ è½½æ–‡æ¡£...")
            # è¿™é‡Œå¯ä»¥æ·»åŠ æ–‡æ¡£åŠ è½½é€»è¾‘
            # ç”±äºåŸé¡¹ç›®ä½¿ç”¨Streamlitä¸Šä¼ ï¼Œè¿™é‡Œæˆ‘ä»¬ä½¿ç”¨Mockæ•°æ®
        
        # åˆ›å»ºMockçŸ¥è¯†åº“æ•°æ®
        self._create_mock_knowledge_base()
        print("âœ… çŸ¥è¯†åº“è®¾ç½®å®Œæˆ")
    
    def _create_mock_knowledge_base(self):
        """
        åˆ›å»ºMockçŸ¥è¯†åº“æ•°æ®ï¼Œç”¨äºæ¼”ç¤ºå¤šè·³æ¨ç†
        """
        mock_documents = [
            {
                "content": "å¼ ä¸‰æ˜¯ä¸€åèµ„æ·±çš„è½¯ä»¶å·¥ç¨‹å¸ˆï¼Œç›®å‰åœ¨åŒ—äº¬ç§‘æŠ€å…¬å¸å·¥ä½œã€‚ä»–æ“…é•¿Pythonå’Œæœºå™¨å­¦ä¹ æŠ€æœ¯ã€‚",
                "metadata": {"source": "å‘˜å·¥æ¡£æ¡ˆ", "type": "ä¸ªäººä¿¡æ¯"}
            },
            {
                "content": "å¼ ä¸‰ä¸æå››åœ¨åŒä¸€ä¸ªé¡¹ç›®ç»„ä¸­åˆä½œï¼Œä»–ä»¬è´Ÿè´£å¼€å‘å…¬å¸çš„AIäº§å“ã€‚",
                "metadata": {"source": "é¡¹ç›®è®°å½•", "type": "å›¢é˜Ÿä¿¡æ¯"}
            },
            {
                "content": "æå››æ˜¯é¡¹ç›®ç»ç†ï¼Œè´Ÿè´£ç®¡ç†é£å¤©é¡¹ç›®çš„æ•´ä½“è¿›åº¦å’Œå›¢é˜Ÿåè°ƒã€‚",
                "metadata": {"source": "é¡¹ç›®è®°å½•", "type": "èŒè´£ä¿¡æ¯"}
            },
            {
                "content": "é£å¤©é¡¹ç›®æ˜¯å…¬å¸çš„é‡ç‚¹AIé¡¹ç›®ï¼Œæ—¨åœ¨å¼€å‘ä¸‹ä¸€ä»£æ™ºèƒ½å¯¹è¯ç³»ç»Ÿã€‚",
                "metadata": {"source": "é¡¹ç›®æ–‡æ¡£", "type": "é¡¹ç›®æè¿°"}
            },
            {
                "content": "é£å¤©é¡¹ç›®å›¢é˜ŸåŒ…æ‹¬å¼ ä¸‰ã€æå››ã€ç‹äº”ç­‰å¤šåå·¥ç¨‹å¸ˆï¼Œé¢„è®¡2024å¹´å®Œæˆã€‚",
                "metadata": {"source": "é¡¹ç›®æ–‡æ¡£", "type": "å›¢é˜Ÿç»„æˆ"}
            },
            {
                "content": "ç‹äº”è´Ÿè´£é£å¤©é¡¹ç›®çš„å‰ç«¯å¼€å‘å·¥ä½œï¼Œä¸å¼ ä¸‰çš„åç«¯å¼€å‘å½¢æˆé…åˆã€‚",
                "metadata": {"source": "é¡¹ç›®è®°å½•", "type": "åˆ†å·¥ä¿¡æ¯"}
            },
            {
                "content": "å…¬å¸è¿˜æœ‰å¦ä¸€ä¸ªé¡¹ç›®å«åšæ˜Ÿè¾°é¡¹ç›®ï¼Œç”±èµµå…­è´Ÿè´£ï¼Œä¸“æ³¨äºæ•°æ®åˆ†æå¹³å°ã€‚",
                "metadata": {"source": "é¡¹ç›®æ–‡æ¡£", "type": "å…¶ä»–é¡¹ç›®"}
            },
            {
                "content": "èµµå…­æ˜¯æ•°æ®ç§‘å­¦å®¶ï¼Œä¸“é—¨è´Ÿè´£æ˜Ÿè¾°é¡¹ç›®çš„ç®—æ³•è®¾è®¡å’Œæ•°æ®å¤„ç†ã€‚",
                "metadata": {"source": "å‘˜å·¥æ¡£æ¡ˆ", "type": "ä¸ªäººä¿¡æ¯"}
            },
            {
                "content": "æå››ä¹‹å‰è¿˜å‚ä¸è¿‡äº‘ç«¯é¡¹ç›®ï¼Œè¯¥é¡¹ç›®å·²äº2023å¹´æˆåŠŸä¸Šçº¿ã€‚",
                "metadata": {"source": "é¡¹ç›®å†å²", "type": "å†å²è®°å½•"}
            },
            {
                "content": "å¼ ä¸‰åœ¨åŠ å…¥é£å¤©é¡¹ç›®ä¹‹å‰ï¼Œæ›¾ç»åœ¨æ™ºèƒ½åŠ©æ‰‹é¡¹ç›®ä¸­æ‹…ä»»æ ¸å¿ƒå¼€å‘è€…ã€‚",
                "metadata": {"source": "å‘˜å·¥æ¡£æ¡ˆ", "type": "å·¥ä½œç»å†"}
            }
        ]
        
        # å°†Mockæ•°æ®æ·»åŠ åˆ°å‘é‡å­˜å‚¨
        for i, doc in enumerate(mock_documents):
            # è°ƒç”¨å‘é‡å­˜å‚¨çš„æ·»åŠ æ–¹æ³•
            success = self.rag_system.vector_store.add_document(
                content=doc["content"],
                metadata=doc["metadata"]
            )
            if success:
                logger.info(f"æ·»åŠ æ–‡æ¡£ {i+1}: {doc['content'][:50]}...")
            else:
                logger.error(f"æ·»åŠ æ–‡æ¡£ {i+1} å¤±è´¥")
        
        print(f"ğŸ“š å·²æ·»åŠ  {len(mock_documents)} ä¸ªæ–‡æ¡£åˆ°çŸ¥è¯†åº“")
    
    def interactive_mode(self):
        """
        äº¤äº’æ¨¡å¼
        """
        print("\nğŸš€ æ¬¢è¿ä½¿ç”¨ Agentic RAG å¤šè·³æ¨ç†ç³»ç»Ÿï¼")
        print("ğŸ’¡ æ”¯æŒçš„æŸ¥è¯¢ç¤ºä¾‹ï¼š")
        print("   - å¼ ä¸‰å‚ä¸äº†å“ªä¸ªé¡¹ç›®ï¼Ÿ")
        print("   - é£å¤©é¡¹ç›®çš„å›¢é˜Ÿæˆå‘˜æœ‰å“ªäº›ï¼Ÿ")
        print("   - æå››è´Ÿè´£ä»€ä¹ˆå·¥ä½œï¼Ÿ")
        print("\nè¾“å…¥ 'quit' æˆ– 'exit' é€€å‡ºç¨‹åº\n")
        
        while True:
            try:
                user_input = input("ğŸ¤– è¯·è¾“å…¥æ‚¨çš„é—®é¢˜: ").strip()
                
                if user_input.lower() in ['quit', 'exit', 'é€€å‡º']:
                    print("ğŸ‘‹ å†è§ï¼")
                    break
                
                if not user_input:
                    continue
                
                print(f"\nğŸ” æ­£åœ¨å¤„ç†æŸ¥è¯¢: {user_input}")
                print("=" * 60)
                
                # å¤„ç†æŸ¥è¯¢
                result = self.process_query(user_input)
                
                # æ˜¾ç¤ºç»“æœ
                self._display_result(result)
                
                print("\n" + "=" * 60 + "\n")
                
            except KeyboardInterrupt:
                print("\nğŸ‘‹ ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­ï¼Œå†è§ï¼")
                break
            except Exception as e:
                logger.error(f"å¤„ç†æŸ¥è¯¢æ—¶å‡ºé”™: {e}")
                print(f"âŒ å¤„ç†æŸ¥è¯¢æ—¶å‡ºé”™: {e}")
    
    def process_query(self, query: str, similarity_threshold: float = None) -> Dict[str, Any]:
        """
        å¤„ç†å•ä¸ªæŸ¥è¯¢
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            similarity_threshold: ç›¸ä¼¼åº¦é˜ˆå€¼
            
        Returns:
            Dict: å¤„ç†ç»“æœ
        """
        if similarity_threshold is None:
            similarity_threshold = DEFAULT_SIMILARITY_THRESHOLD
        
        try:
            result = self.rag_system.process_query(query, similarity_threshold)
            return result
        except Exception as e:
            logger.error(f"æŸ¥è¯¢å¤„ç†å¤±è´¥: {e}")
            return {
                'error': str(e),
                'user_query': query
            }
    
    def _display_result(self, result: Dict[str, Any]):
        """
        æ˜¾ç¤ºæŸ¥è¯¢ç»“æœ
        
        Args:
            result: æŸ¥è¯¢ç»“æœ
        """
        if 'error' in result:
            print(f"âŒ é”™è¯¯: {result['error']}")
            return
        
        analysis = result.get('analysis', {})
        plan = result.get('plan', {})
        
        # æ˜¾ç¤ºæŸ¥è¯¢è§„åˆ’
        print(f"ğŸ“‹ æŸ¥è¯¢ç±»å‹: {plan.get('query_type', 'unknown')}")
        print(f"ğŸ¯ å…³é”®å®ä½“: {', '.join(plan.get('key_entities', []))}")
        print(f"ğŸ”„ è¿­ä»£æ¬¡æ•°: {result.get('iterations', 0)}")
        print(f"ğŸ“š æ£€ç´¢æ–‡æ¡£æ•°: {result.get('total_documents', 0)}")
        
        # æ˜¾ç¤ºæ¨ç†é“¾æ¡
        reasoning_chain = analysis.get('reasoning_chain', [])
        if reasoning_chain:
            print("\nğŸ§  æ¨ç†é“¾æ¡:")
            for i, step in enumerate(reasoning_chain, 1):
                print(f"   {i}. {step.get('fact', '')}")
                if step.get('source'):
                    print(f"      ğŸ“– æ¥æº: {step['source']}")
        
        # æ˜¾ç¤ºæœ€ç»ˆç»“è®º
        conclusion = analysis.get('conclusion', '')
        if conclusion:
            print(f"\nâœ… æœ€ç»ˆç­”æ¡ˆ: {conclusion}")
        
        # æ˜¾ç¤ºç½®ä¿¡åº¦
        confidence = analysis.get('confidence', 0)
        print(f"ğŸ“Š ç½®ä¿¡åº¦: {confidence:.2f}")
        
        # æ˜¾ç¤ºç¼ºå¤±ä¿¡æ¯
        missing_info = analysis.get('missing_info', [])
        if missing_info:
            print(f"âš ï¸ ç¼ºå¤±ä¿¡æ¯: {', '.join(missing_info)}")
    
    def batch_mode(self, queries_file: str, output_file: str = None):
        """
        æ‰¹å¤„ç†æ¨¡å¼
        
        Args:
            queries_file: æŸ¥è¯¢æ–‡ä»¶è·¯å¾„
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        try:
            with open(queries_file, 'r', encoding='utf-8') as f:
                queries = [line.strip() for line in f if line.strip()]
            
            results = []
            
            for i, query in enumerate(queries, 1):
                print(f"\nå¤„ç†æŸ¥è¯¢ {i}/{len(queries)}: {query}")
                result = self.process_query(query)
                results.append(result)
            
            if output_file:
                with open(output_file, 'w', encoding='utf-8') as f:
                    json.dump(results, f, ensure_ascii=False, indent=2)
                print(f"\nç»“æœå·²ä¿å­˜åˆ°: {output_file}")
            else:
                for result in results:
                    self._display_result(result)
                    print("\n" + "-" * 40 + "\n")
                    
        except FileNotFoundError:
            print(f"âŒ æ–‡ä»¶æœªæ‰¾åˆ°: {queries_file}")
        except Exception as e:
            logger.error(f"æ‰¹å¤„ç†å¤±è´¥: {e}")
            print(f"âŒ æ‰¹å¤„ç†å¤±è´¥: {e}")

def main():
    """
    ä¸»å‡½æ•°
    """
    parser = argparse.ArgumentParser(
        description="Agentic RAG å¤šè·³æ¨ç†ç³»ç»Ÿ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  python cli_app.py                          # äº¤äº’æ¨¡å¼
  python cli_app.py -q "å¼ ä¸‰å‚ä¸äº†å“ªä¸ªé¡¹ç›®ï¼Ÿ"    # å•æ¬¡æŸ¥è¯¢
  python cli_app.py -b queries.txt           # æ‰¹å¤„ç†æ¨¡å¼
  python cli_app.py --setup-kb               # è®¾ç½®çŸ¥è¯†åº“
        """
    )
    
    parser.add_argument(
        '-q', '--query',
        type=str,
        help='å•æ¬¡æŸ¥è¯¢æ¨¡å¼'
    )
    
    parser.add_argument(
        '-b', '--batch',
        type=str,
        help='æ‰¹å¤„ç†æ¨¡å¼ï¼ŒæŒ‡å®šæŸ¥è¯¢æ–‡ä»¶è·¯å¾„'
    )
    
    parser.add_argument(
        '-o', '--output',
        type=str,
        help='è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆæ‰¹å¤„ç†æ¨¡å¼ï¼‰'
    )
    
    parser.add_argument(
        '--setup-kb',
        action='store_true',
        help='è®¾ç½®çŸ¥è¯†åº“'
    )
    
    parser.add_argument(
        '--threshold',
        type=float,
        default=DEFAULT_SIMILARITY_THRESHOLD,
        help=f'ç›¸ä¼¼åº¦é˜ˆå€¼ (é»˜è®¤: {DEFAULT_SIMILARITY_THRESHOLD})'
    )
    
    parser.add_argument(
        '--docs-path',
        type=str,
        help='æ–‡æ¡£è·¯å¾„ï¼ˆè®¾ç½®çŸ¥è¯†åº“æ—¶ä½¿ç”¨ï¼‰'
    )
    
    args = parser.parse_args()
    
    # æ£€æŸ¥APIå¯†é’¥
    if DEEPSEEK_API_KEY == "sk-your-deepseek-api-key":
        print("âŒ è¯·åœ¨ config/settings.py ä¸­è®¾ç½®æ­£ç¡®çš„ DEEPSEEK_API_KEY")
        sys.exit(1)
    
    # åˆ›å»ºCLIåº”ç”¨
    app = AgenticRAGCLI()
    
    try:
        if args.setup_kb:
            # è®¾ç½®çŸ¥è¯†åº“æ¨¡å¼
            app.setup_knowledge_base(args.docs_path)
        elif args.query:
            # å•æ¬¡æŸ¥è¯¢æ¨¡å¼
            app.setup_knowledge_base()  # ç¡®ä¿çŸ¥è¯†åº“å·²è®¾ç½®
            print(f"ğŸ” å¤„ç†æŸ¥è¯¢: {args.query}")
            result = app.process_query(args.query, args.threshold)
            app._display_result(result)
        elif args.batch:
            # æ‰¹å¤„ç†æ¨¡å¼
            app.setup_knowledge_base()  # ç¡®ä¿çŸ¥è¯†åº“å·²è®¾ç½®
            app.batch_mode(args.batch, args.output)
        else:
            # äº¤äº’æ¨¡å¼ï¼ˆé»˜è®¤ï¼‰
            app.setup_knowledge_base()  # ç¡®ä¿çŸ¥è¯†åº“å·²è®¾ç½®
            app.interactive_mode()
            
    except KeyboardInterrupt:
        print("\nğŸ‘‹ ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        logger.error(f"ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        print(f"âŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()